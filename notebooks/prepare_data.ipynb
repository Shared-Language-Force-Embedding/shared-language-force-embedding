{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble\n",
    "import numpy as np\n",
    "from phrase_trials_dataset import PhraseForceTrialDataset\n",
    "\n",
    "ANGLE = 5.0 * np.pi / 4.0\n",
    "TRANSFORMATION = np.array([\n",
    "    [np.cos(ANGLE), -np.sin(ANGLE), 0.0],\n",
    "    [np.sin(ANGLE),  np.sin(ANGLE), 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "phrase2force_dataset = PhraseForceTrialDataset('../data/phrase2force', TRANSFORMATION)\n",
    "phrase2force_dataset[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEADBAND = 0.5\n",
    "\n",
    "everyone = pd.concat(phrase2force_dataset[:], ignore_index=True)\n",
    "\n",
    "EXTERNAL_FORCE_COLUMNS = [f'external_force_{i}' for i in range(3)]\n",
    "\n",
    "all_forces = everyone[EXTERNAL_FORCE_COLUMNS]\n",
    "\n",
    "all_significant_forces = all_forces.where(all_forces.abs() > DEADBAND)\n",
    "\n",
    "ALL_SIGNIFICANT_FORCES_MEANS = all_significant_forces.mean(axis=0, skipna=True)\n",
    "ALL_SIGNIFICANT_FORCES_STD = all_significant_forces.std(axis=0, skipna=True)\n",
    "\n",
    "print(ALL_SIGNIFICANT_FORCES_MEANS)\n",
    "print(ALL_SIGNIFICANT_FORCES_STD)\n",
    "\n",
    "all_significant_forces.hist(bins=100, figsize=(12, 8))\n",
    "plt.suptitle('Histograms of Significant Forces')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_trial(trial):\n",
    "    indices = np.arange(len(trial))\n",
    "    filtered_indices = indices[(trial[EXTERNAL_FORCE_COLUMNS].abs() > DEADBAND).any(axis=1)]\n",
    "    first, last = filtered_indices[0], filtered_indices[-1]\n",
    "    pre_trial, trimmed_trial, post_trial = trial.iloc[:first].copy(), trial.iloc[first:last+1].copy(), trial.iloc[last+1:].copy()\n",
    "    for trial in [pre_trial, trimmed_trial, post_trial]:\n",
    "        trial['time'] = trial['time'] - trial['time'].min()\n",
    "    return pre_trial if len(pre_trial) > 0 else None, trimmed_trial if len(trimmed_trial) > 0 else None, post_trial if len(post_trial) > 0 else None\n",
    "\n",
    "def resample_trial(trial, N=200):\n",
    "    if trial is None:\n",
    "        return None\n",
    "    resampled_trial = pd.DataFrame()\n",
    "    resampled_trial['time'] = np.linspace(trial['time'].min(), trial['time'].max(), N)\n",
    "    for external_force_column in EXTERNAL_FORCE_COLUMNS:\n",
    "        resampled_trial[external_force_column] = np.interp(resampled_trial['time'], trial['time'], trial[external_force_column])\n",
    "    return resampled_trial\n",
    "\n",
    "original_trial = phrase2force_dataset[4,35]\n",
    "pre_trial, trimmed_trial, post_trial = trim_trial(original_trial)\n",
    "resampled_pre_trial, resampled_trial, resampled_post_trial = resample_trial(pre_trial), resample_trial(trimmed_trial), resample_trial(post_trial)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(original_trial['time'], original_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(pre_trial['time'], pre_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(resampled_trial['time'], resampled_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(post_trial['time'], post_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_trial(trial):\n",
    "    if trial is None:\n",
    "        return None\n",
    "    standardized_trial = trial.copy()\n",
    "    for external_force_column in EXTERNAL_FORCE_COLUMNS:\n",
    "        standardized_trial[external_force_column] = (trial[external_force_column] - ALL_SIGNIFICANT_FORCES_MEANS[external_force_column]) / ALL_SIGNIFICANT_FORCES_STD[external_force_column]\n",
    "    return standardized_trial\n",
    "\n",
    "standardized_and_resampled_pre_trial, standardized_and_resampled_trial, standardized_and_resampled_post_trial = standardize_trial(resampled_pre_trial), standardize_trial(resampled_trial), standardize_trial(resampled_post_trial)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(standardized_and_resampled_pre_trial['time'], standardized_and_resampled_pre_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Standardized and Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(standardized_and_resampled_trial['time'], standardized_and_resampled_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Standardized and Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(len(EXTERNAL_FORCE_COLUMNS)):\n",
    "    plt.plot(standardized_and_resampled_post_trial['time'], standardized_and_resampled_post_trial[f'external_force_{i}'], label=f'External Force {i}', color='rgb'[i])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Force')\n",
    "plt.title('Standardized and Resampled Force Components Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "VOCABULARY = {\n",
    "    'adverb': [\n",
    "        'slightly',\n",
    "        'greatly',\n",
    "        'smoothly',\n",
    "        'sharply',\n",
    "        'slowly',\n",
    "        'quickly',\n",
    "        'lightly',\n",
    "        'significantly',\n",
    "        'softly',\n",
    "        'harshly',\n",
    "        'gradually',\n",
    "        'immediately',\n",
    "    ],\n",
    "    'direction': {\n",
    "        'X': {\n",
    "            'left': [\n",
    "                'left',\n",
    "                'leftward',\n",
    "                'to the left'\n",
    "            ],\n",
    "            \n",
    "            'right': [\n",
    "                'right',\n",
    "                'rightward',\n",
    "                'to the right',\n",
    "            ],\n",
    "        },\n",
    "        'Y': {\n",
    "            'forward': [\n",
    "                'forward',\n",
    "                'ahead',\n",
    "                'to the front',\n",
    "            ],\n",
    "            'backward': [\n",
    "                'backward',\n",
    "                'behind',\n",
    "                'to the back',\n",
    "            ],\n",
    "        },\n",
    "        'Z': {\n",
    "            'up': [\n",
    "                'up',\n",
    "                'upward',\n",
    "                'above',\n",
    "            ],\n",
    "            'down': [\n",
    "                'down',\n",
    "                'downward',\n",
    "                'below',\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "CARTESIAN_AXES = set(VOCABULARY['direction'].keys())\n",
    "CARTESIAN_DIRECTIONS = {direction for axes_directions in VOCABULARY['direction'].values() for direction in axes_directions.keys()}\n",
    "CARTESIAN_DIRECTION_TO_AXIS = {direction: axis for axis, axis_directions in VOCABULARY['direction'].items() for direction in axis_directions.keys()}\n",
    "DIRECTION_PART_TO_AXIS = {direction_part: axis for axis, axis_directions in VOCABULARY['direction'].items() for direction_parts in axis_directions.values() for direction_part in direction_parts}\n",
    "DIRECTION_PART_TO_CARTESIAN_DIRECTION = {direction_part: direction for axis_directions in VOCABULARY['direction'].values() for direction, direction_parts in axis_directions.items() for direction_part in direction_parts}\n",
    "\n",
    "ADVERBS = sorted(VOCABULARY['adverb'] + [''])\n",
    "\n",
    "CARTESIAN_DIRECTIONS = sorted(list(CARTESIAN_DIRECTIONS) + [''])\n",
    "\n",
    "print(ADVERBS)\n",
    "print(CARTESIAN_DIRECTIONS)\n",
    "\n",
    "def encode_phrase(adverb, first_cartesian_direction, second_carteisian_direction):\n",
    "    def one_hot_encode(value, categories):\n",
    "        one_hot_vector = torch.zeros(len(categories))\n",
    "        if value in categories:\n",
    "            one_hot_vector[categories.index(value)] = 1\n",
    "        else:\n",
    "            raise ValueError(f'value {value} not in categories {categories}')\n",
    "        return one_hot_vector\n",
    "\n",
    "    while adverb not in ADVERBS:\n",
    "        adverb = input(f\"Invalid adverb '{adverb}'. Please enter a valid adverb: \")\n",
    "\n",
    "    while first_cartesian_direction not in CARTESIAN_DIRECTIONS:\n",
    "        first_cartesian_direction = input(f\"Invalid direction '{first_cartesian_direction}'. Please enter a valid direction: \")\n",
    "\n",
    "    while second_carteisian_direction not in CARTESIAN_DIRECTIONS:\n",
    "        second_carteisian_direction = input(f\"Invalid direction '{second_carteisian_direction}'. Please enter a valid direction: \")\n",
    "\n",
    "    adverb_one_hot = one_hot_encode(adverb, ADVERBS)\n",
    "    first_direction_one_hot = one_hot_encode(first_cartesian_direction, CARTESIAN_DIRECTIONS)\n",
    "    second_direction_one_hot = one_hot_encode(second_carteisian_direction, CARTESIAN_DIRECTIONS)\n",
    "\n",
    "    phrase_one_hot = torch.cat((adverb_one_hot, first_direction_one_hot, second_direction_one_hot))\n",
    "\n",
    "    return phrase_one_hot, adverb_one_hot, first_direction_one_hot, second_direction_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compose_multimodal_pair(trial):\n",
    "    pre_trial, trimmed_trial, post_trial = trim_trial(trial)\n",
    "    resampled_pre_trial, resampled_trial, resampled_post_trial = resample_trial(pre_trial), resample_trial(trimmed_trial), resample_trial(post_trial)\n",
    "    standardized_and_resampled_pre_trial, standardized_and_resampled_trial, standardized_and_resampled_post_trial = standardize_trial(resampled_pre_trial), standardize_trial(resampled_trial), standardize_trial(resampled_post_trial)\n",
    "\n",
    "    force_time_series_tensor_pre_trial, force_time_series_tensor_trial, force_time_series_tensor_post_trial = torch.tensor(standardized_and_resampled_pre_trial.values, dtype=torch.float32).T if standardized_and_resampled_pre_trial is not None else None, torch.tensor(standardized_and_resampled_trial.values, dtype=torch.float32).T if standardized_and_resampled_trial is not None else None, torch.tensor(standardized_and_resampled_post_trial.values, dtype=torch.float32).T if standardized_and_resampled_post_trial is not None else None\n",
    "\n",
    "    phrase, adverb, first_cartesian_direction, second_cartesian_direction = trial[['phrase', 'adverb', 'first_cartesian_direction', 'second_cartesian_direction']].iloc[0]\n",
    "    phrase_one_hot, adverb_one_hot, first_cartesian_direction_one_hot, second_cartesian_direction_one_hot = encode_phrase(adverb, first_cartesian_direction, second_cartesian_direction)\n",
    "\n",
    "    no_action_phrase, no_action_adverb, no_action_first_cartesian_direction, no_action_second_cartesian_direction = ['']*4\n",
    "    no_action_phrase_one_hot, no_action_adverb_one_hot, no_action_first_cartesian_direction_one_hot, no_action_second_cartesian_direction_one_hot = encode_phrase(no_action_adverb, no_action_first_cartesian_direction, no_action_second_cartesian_direction)\n",
    "\n",
    "    return {\n",
    "        'force': force_time_series_tensor_pre_trial,\n",
    "\n",
    "        'phrase': no_action_phrase,\n",
    "        'phrase_one_hot': no_action_phrase_one_hot,\n",
    "\n",
    "        'adverb': no_action_adverb,\n",
    "        'adverb_one_hot': no_action_adverb_one_hot,\n",
    "\n",
    "        'first_cartesian_direction': no_action_first_cartesian_direction,\n",
    "        'first_cartesian_direction_one_hot': no_action_first_cartesian_direction_one_hot,\n",
    "        \n",
    "        'second_cartesian_direction': no_action_second_cartesian_direction,\n",
    "        'second_cartesian_direction_one_hot': no_action_second_cartesian_direction_one_hot,\n",
    "    } if force_time_series_tensor_pre_trial is not None else None, {\n",
    "        'force': force_time_series_tensor_trial,\n",
    "\n",
    "        'phrase': phrase,\n",
    "        'phrase_one_hot': phrase_one_hot,\n",
    "\n",
    "        'adverb': adverb,\n",
    "        'adverb_one_hot': adverb_one_hot,\n",
    "\n",
    "        'first_cartesian_direction': first_cartesian_direction,\n",
    "        'first_cartesian_direction_one_hot': first_cartesian_direction_one_hot,\n",
    "\n",
    "        'second_cartesian_direction': second_cartesian_direction,\n",
    "        'second_cartesian_direction_one_hot': second_cartesian_direction_one_hot,\n",
    "    } if force_time_series_tensor_trial is not None else None, {\n",
    "        'force': force_time_series_tensor_post_trial,\n",
    "\n",
    "        'phrase': no_action_phrase,\n",
    "        'phrase_one_hot': no_action_phrase_one_hot,\n",
    "\n",
    "        'adverb': no_action_adverb,\n",
    "        'adverb_one_hot': no_action_adverb_one_hot,\n",
    "\n",
    "        'first_cartesian_direction': no_action_first_cartesian_direction,\n",
    "        'first_cartesian_direction_one_hot': no_action_first_cartesian_direction_one_hot,\n",
    "        \n",
    "        'second_cartesian_direction': no_action_second_cartesian_direction,\n",
    "        'second_cartesian_direction_one_hot': no_action_second_cartesian_direction_one_hot,\n",
    "    } if force_time_series_tensor_post_trial is not None else None\n",
    "\n",
    "import os\n",
    "\n",
    "def save_multimodal_pairs(trials, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    unique_id = 0\n",
    "    for i, trial in enumerate(trials):\n",
    "        for j, multimodal_pair in enumerate(compose_multimodal_pair(trial)):\n",
    "            if multimodal_pair is not None:\n",
    "                save_path = os.path.join(save_dir, f'{unique_id}__multimodal_pair.pt' if j == 1 else f'{unique_id}__multimodal_pair__no_action.pt')\n",
    "                torch.save(multimodal_pair, save_path)\n",
    "            unique_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_multimodal_pairs(phrase2force_dataset[:], '../data/global_standardized_and_absolute_time_channel_multimodal_pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# class Timer:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.reset()\n",
    "\n",
    "#     def dt(self) -> float:\n",
    "#         t = self.t()\n",
    "#         dt = t - self.last_t\n",
    "#         self.last_t = t\n",
    "#         return dt\n",
    "\n",
    "#     def t(self) -> float:\n",
    "#         return time.time() - self.start_time\n",
    "\n",
    "#     def reset(self) -> None:\n",
    "#         self.start_time = time.time()\n",
    "#         self.last_t = 0.0\n",
    "\n",
    "\n",
    "# class ForceCurve:\n",
    "#     def __init__(self, direction, duration, peak_force, ramp_up_pct=0.5, hold_pct=0.0, ramp_down_pct=0.5):\n",
    "#         self.direction = direction\n",
    "#         self.ramp_up_time = ramp_up_pct * duration\n",
    "#         self.hold_time = hold_pct * duration\n",
    "#         self.ramp_down_time = ramp_down_pct * duration\n",
    "#         self.duration = duration\n",
    "#         self.peak_force = peak_force\n",
    "#         self.start_time = 0.0\n",
    "#         self.stop_time = 0.0\n",
    "    \n",
    "#     def start(self):\n",
    "#         self.start_time = time.time()\n",
    "    \n",
    "#     def stop(self):\n",
    "#         self.stop_time = time.time()\n",
    "    \n",
    "#     def get_force(self):\n",
    "#         t = time.time() - self.start_time\n",
    "#         if t <= self.ramp_up_time:\n",
    "#             magnitude = self.peak_force * t / self.ramp_up_time\n",
    "#         elif t <= self.hold_time:\n",
    "#             magnitude = self.peak_force\n",
    "#         elif t <= self.ramp_down_time:\n",
    "#             magnitude = self.peak_force * (1.0 - (t - self.ramp_up_time - self.hold_time) / self.ramp_down_time)\n",
    "#         else:\n",
    "#             magnitude = 0.0\n",
    "        \n",
    "#         is_done = t > self.duration\n",
    "#         if is_done:\n",
    "#             self.stop()\n",
    "\n",
    "#         return self.direction * magnitude, is_done\n",
    "\n",
    "# force2phrase_dataset = PhraseForceTrialDataset('../data/force2phrase', TRANSFORMATION)\n",
    "\n",
    "# for i in range(len(force2phrase_dataset)):\n",
    "#     force2phrase_dataset[i].drop(columns=['external_force_0', 'external_force_1', 'external_force_2'], inplace=True)\n",
    "\n",
    "#     force2phrase_dataset[i].rename(columns={\n",
    "#         'internal_force_0': 'external_force_0',\n",
    "#         'internal_force_1': 'external_force_1',\n",
    "#         'internal_force_2': 'external_force_2'\n",
    "#     }, inplace=True)\n",
    "\n",
    "# everyone_with_force2phrase = pd.concat(phrase2force_dataset[:] + force2phrase_dataset[:], ignore_index=True)\n",
    "\n",
    "# all_forces = everyone_with_force2phrase[EXTERNAL_FORCE_COLUMNS]\n",
    "\n",
    "# all_significant_forces = all_forces.where(all_forces.abs() > DEADBAND)\n",
    "\n",
    "# ALL_SIGNIFICANT_FORCES_MEANS = all_significant_forces.mean(axis=0, skipna=True)\n",
    "# ALL_SIGNIFICANT_FORCES_STD = all_significant_forces.std(axis=0, skipna=True)\n",
    "\n",
    "# print(ALL_SIGNIFICANT_FORCES_MEANS)\n",
    "# print(ALL_SIGNIFICANT_FORCES_STD)\n",
    "\n",
    "# save_multimodal_pairs(phrase2force_dataset[:] + force2phrase_dataset[:], '../data/global_standardized_with_force2phrase_and_absolute_time_channel_multimodal_pairs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared-language-force-embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
