{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble\n",
    "import numpy as np\n",
    "from dataset import Dataset\n",
    "from model import DualAutoencoderModel\n",
    "from embedder import BinaryEmbedder, GloveEmbedder, SBERTEmbedder, SVMKNNEmbedder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = [\n",
    "    '',\n",
    "    'slightly',\n",
    "    'greatly',\n",
    "    'smoothly',\n",
    "    'sharply',\n",
    "    'slowly',\n",
    "    'quickly',\n",
    "    'lightly',\n",
    "    'significantly',\n",
    "    'softly',\n",
    "    'harshly',\n",
    "    'gradually',\n",
    "    'immediately',\n",
    "]\n",
    "\n",
    "directions = [\n",
    "    'backward',\n",
    "    'backward down',\n",
    "    'backward left',\n",
    "    'backward right',\n",
    "    'backward up',\n",
    "    'down',\n",
    "    'down forward',\n",
    "    'down left',\n",
    "    'down right',\n",
    "    'forward',\n",
    "    'forward left',\n",
    "    'forward right',\n",
    "    'forward up',\n",
    "    'left',\n",
    "    'left up',\n",
    "    'right',\n",
    "    'right up',\n",
    "    'up',\n",
    "]\n",
    "\n",
    "VOCABULARY = [(f'Move {modifier} {direction}.', np.array([modifier, direction.split(' ')[0], direction.split(' ')[-1] if 'and' in direction else ''], dtype='U16'))\n",
    "              for modifier in modifiers for direction in directions]\n",
    "VOCABULARY += [('', np.array(['', '', ''], dtype='U16'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('../data/trimmed_trials')\n",
    "\n",
    "force_data, phrase_data = dataset.load()\n",
    "merged_phrase_data = dataset.merge_directions(phrase_data)\n",
    "\n",
    "binary_embedder = BinaryEmbedder(np.unique(merged_phrase_data), merged_phrase_data.shape[-1])\n",
    "sbert_embedder = SBERTEmbedder(VOCABULARY)\n",
    "glove_embedder = GloveEmbedder('../data/limited_vocab_embeddings_with_special_no_word_token_50d.pt', phrase_data.shape[-1])\n",
    "\n",
    "dae_b = DualAutoencoderModel(binary_embedder)\n",
    "dae_g = DualAutoencoderModel(glove_embedder, phrase_mse_loss=True)\n",
    "\n",
    "dae_b.train(force_data, merged_phrase_data, epochs=1024, verbose=True)\n",
    "dae_g.train(force_data, phrase_data, epochs=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dae_b.pkl', 'wb') as file:\n",
    "    pickle.dump(dae_b, file)\n",
    "\n",
    "with open('dae_g.pkl', 'wb') as file:\n",
    "    pickle.dump(dae_g, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
