{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataset import Dataset\n",
    "from model import SVMKNNModel, MLPModel, DualAutoencoderModel\n",
    "from embedder import SVMKNNEmbedder, BinaryEmbedder, GloveEmbedder\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_EMBEDDINGS_PATH = '../data/limited_vocab_embeddings_with_special_no_word_token_50d.pt'\n",
    "DATASET_PATH = '../data/trimmed_trials'\n",
    "\n",
    "metrics = Metrics()\n",
    "dataset = Dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(force_data: NDArray, phrase_data: NDArray, merged_phrase_data: NDArray, exclude_modifier: str = None, exclude_direction: str = None, exclude_composites: bool = False, seed: int = 0, verbose: bool = False, graph_index: int = -1):\n",
    "    embedders = [\n",
    "        SVMKNNEmbedder(np.unique(merged_phrase_data), merged_phrase_data.shape[-1]),\n",
    "        BinaryEmbedder(np.unique(merged_phrase_data), merged_phrase_data.shape[-1]),\n",
    "        GloveEmbedder(GLOVE_EMBEDDINGS_PATH, phrase_data.shape[-1]),\n",
    "        BinaryEmbedder(np.unique(merged_phrase_data), merged_phrase_data.shape[-1]),\n",
    "        GloveEmbedder(GLOVE_EMBEDDINGS_PATH, phrase_data.shape[-1]),\n",
    "    ]\n",
    "    models = [\n",
    "        SVMKNNModel(embedders[0]),\n",
    "        MLPModel(embedders[1]),\n",
    "        MLPModel(embedders[2], phrase_mse_loss=True),\n",
    "        DualAutoencoderModel(embedders[3]),\n",
    "        DualAutoencoderModel(embedders[4], phrase_mse_loss=True),\n",
    "    ]\n",
    "\n",
    "    force_datas = [force_data, force_data, force_data, force_data, force_data]\n",
    "    phrase_datas = [merged_phrase_data, merged_phrase_data, phrase_data, merged_phrase_data, phrase_data]\n",
    "    epochs = [0, 1024, 1024, 1024, 1024]\n",
    "\n",
    "    if exclude_modifier is not None:\n",
    "        force_trains, force_tests, phrase_trains, phrase_tests = [], [], [], []\n",
    "        for force_data, phrase_data in zip(force_datas, phrase_datas):\n",
    "            force_trains.append(force_data[phrase_data[:, 0] != exclude_modifier])\n",
    "            force_tests.append(force_data[phrase_data[:, 0] == exclude_modifier])\n",
    "            phrase_trains.append(phrase_data[phrase_data[:, 0] != exclude_modifier])\n",
    "            phrase_tests.append(phrase_data[phrase_data[:, 0] == exclude_modifier])\n",
    "    elif exclude_direction is not None:\n",
    "        force_trains, force_tests, phrase_trains, phrase_tests = [], [], [], []\n",
    "        for force_data, phrase_data in zip(force_datas, phrase_datas):\n",
    "            force_trains.append(force_data[merged_phrase_data[:, 1] != exclude_direction])\n",
    "            force_tests.append(force_data[merged_phrase_data[:, 1] == exclude_direction])\n",
    "            phrase_trains.append(phrase_data[merged_phrase_data[:, 1] != exclude_direction])\n",
    "            phrase_tests.append(phrase_data[merged_phrase_data[:, 1] == exclude_direction])\n",
    "    elif exclude_composites:\n",
    "        force_trains, force_tests, phrase_trains, phrase_tests = [], [], [], []\n",
    "        for force_data, phrase_data in zip(force_datas, phrase_datas):\n",
    "            force_trains.append(force_data[np.char.find(merged_phrase_data[:, 1], ' ') == -1])\n",
    "            force_tests.append(force_data[np.char.find(merged_phrase_data[:, 1], ' ') != -1])\n",
    "            phrase_trains.append(phrase_data[np.char.find(merged_phrase_data[:, 1], ' ') == -1])\n",
    "            phrase_tests.append(phrase_data[np.char.find(merged_phrase_data[:, 1], ' ') != -1])\n",
    "    else:\n",
    "        force_trains, force_tests, phrase_trains, phrase_tests = zip(*[train_test_split(force, phrase, train_size=0.9, random_state=seed) for force, phrase in zip(force_datas, phrase_datas)])\n",
    "\n",
    "    for model, force_train, phrase_train, epoch in zip(models, force_trains, phrase_trains, epochs):\n",
    "        model.train(force_train, phrase_train, epoch, verbose)\n",
    "\n",
    "    force_predictions = [model.phrase_to_force(phrase_test) for model, phrase_test in zip(models, phrase_tests)]\n",
    "    phrase_predictions = [model.force_to_phrase(force_test) for model, force_test in zip(models, force_tests)]\n",
    "\n",
    "    modifier_similarities = [[] for _ in models]\n",
    "    direction_similarities = [[] for _ in models]\n",
    "    curve_shape_acc = [[] for _ in models]\n",
    "    agg_dir_acc = [[] for _ in models]\n",
    "\n",
    "    for i in range(phrase_predictions[0].shape[0]):\n",
    "        if verbose:\n",
    "            print(f'{' '.join(phrase_tests[0][i]).strip():30}', end='')\n",
    "        for j, phrase_prediction in enumerate(phrase_predictions):\n",
    "            modifier_similarity = metrics.score_modifier(phrase_tests[0][i], phrase_prediction[i])\n",
    "            direction_similarity = metrics.score_direction(phrase_tests[0][i], phrase_prediction[i])\n",
    "\n",
    "            modifier_similarities[j].append(modifier_similarity)\n",
    "            direction_similarities[j].append(direction_similarity)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'({modifier_similarity:.4f}) ({direction_similarity:.4f}) {' '.join(phrase_prediction[i]).strip():30}', end='')\n",
    "        if verbose:\n",
    "            print('')\n",
    "    if verbose:\n",
    "        print('')\n",
    "\n",
    "    for i in range(force_predictions[0].shape[0]):\n",
    "        for j, force_prediction in enumerate(force_predictions):\n",
    "            mse = metrics.score_force_profile(force_tests[j][i], force_prediction[i])\n",
    "            dir_sim = metrics.score_force_profile_direction(force_tests[j][i], force_prediction[i])\n",
    "\n",
    "            curve_shape_acc[j].append(mse)\n",
    "            agg_dir_acc[j].append(dir_sim)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'{f'{mse:.4f}':15}', end='')\n",
    "        if verbose:\n",
    "            print('')\n",
    "    if verbose:\n",
    "        print('')\n",
    "\n",
    "    mod_sim = np.mean(np.array(modifier_similarities), axis=1)\n",
    "    dir_sim = np.mean(np.array(direction_similarities), axis=1)\n",
    "    phrase_sim = 0.5 * (mod_sim + dir_sim)\n",
    "    fp_acc = np.mean(np.array(curve_shape_acc), axis=1)\n",
    "    fd_acc = np.mean(np.array(agg_dir_acc), axis=1)\n",
    "    return np.array([mod_sim, dir_sim, phrase_sim, fp_acc, fd_acc])\n",
    "\n",
    "def plot_results(results: NDArray, title: str = '') -> None:\n",
    "    results = results[[3, 4, 0, 1, 2]]\n",
    "\n",
    "    cutoff = 2.0\n",
    "    z_scores = np.apply_along_axis(scipy.stats.zscore, 1, results)\n",
    "    z_scores[0] = -z_scores[0]\n",
    "\n",
    "    model_labels = [\"$SVM/KNN$\", \"$DMLP_B$\", \"$DMLP_G$\", \"$DAE_B$\", \"$DAE_G$\"]\n",
    "    metric_labels = [\"FPAcc\", \"FDAcc\", \"ModSim\", \"DirSim\", \"PhraseSim\"]\n",
    "\n",
    "    plt.figure(figsize=(7, 3.5))\n",
    "    ax = sns.heatmap(\n",
    "        z_scores, vmin=-cutoff, vmax=cutoff, cmap=\"RdYlGn\", annot=results, fmt=\".3f\", linewidths=0.625,\n",
    "        cbar=True, xticklabels=model_labels, yticklabels=metric_labels, annot_kws={\"size\": 16}, cbar_kws={'label': '$z$-score'})\n",
    "    ax.xaxis.set_label_position('bottom')\n",
    "    ax.tick_params(axis='x', labelsize=14.5)\n",
    "    ax.tick_params(axis='y', labelsize=14.5)\n",
    "    plt.title(title, fontsize=14.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "\n",
    "force_data, phrase_data = dataset.load()\n",
    "merged_phrase_data = dataset.merge_directions(phrase_data)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for seed in range(N):\n",
    "    torch.manual_seed(seed)\n",
    "    results = get_results(force_data, phrase_data, merged_phrase_data, seed=seed, verbose=False)\n",
    "    final_results.append(results)\n",
    "    plot_results(results, f\"Model Scores for In-Distribution Samples (Seed {seed})\")\n",
    "\n",
    "plot_results(np.mean(final_results, axis=0), \"Mean Model Scores for In-Distribution Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = [\n",
    "    'slightly',\n",
    "    'greatly',\n",
    "    'smoothly',\n",
    "    'sharply',\n",
    "    'slowly',\n",
    "    'quickly',\n",
    "    'lightly',\n",
    "    'significantly',\n",
    "    'softly',\n",
    "    'harshly',\n",
    "    'gradually',\n",
    "    'immediately',\n",
    "]\n",
    "\n",
    "force_data, phrase_data = dataset.load()\n",
    "merged_phrase_data = dataset.merge_directions(phrase_data)\n",
    "\n",
    "modifier_results = {}\n",
    "\n",
    "for modifier in modifiers:\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    N = 1\n",
    "    modifier_results[modifier] = 0.0\n",
    "\n",
    "    for _ in range(N):\n",
    "        modifier_results[modifier] += get_results(force_data, phrase_data, merged_phrase_data, exclude_modifier=modifier, verbose=False)\n",
    "\n",
    "    modifier_results[modifier] /= N\n",
    "    plot_results(modifier_results[modifier], f\"Model Scores on Out-of-Distribution Modifiers ('{modifier}')\")\n",
    "\n",
    "plot_results(np.mean([modifier_results[modifier] for modifier in modifier_results], axis=0), \"Model Scores on Out-of-Distribution Modifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\n",
    "    'backward',\n",
    "    'backward down',\n",
    "    'backward left',\n",
    "    'backward right',\n",
    "    'backward up',\n",
    "    'down',\n",
    "    'down forward',\n",
    "    'down left',\n",
    "    'down right',\n",
    "    'forward',\n",
    "    'forward left',\n",
    "    'forward right',\n",
    "    'forward up',\n",
    "    'left',\n",
    "    'left up',\n",
    "    'right',\n",
    "    'right up',\n",
    "    'up',\n",
    "]\n",
    "\n",
    "force_data, phrase_data = dataset.load()\n",
    "merged_phrase_data = dataset.merge_directions(phrase_data)\n",
    "\n",
    "direction_results = {}\n",
    "\n",
    "for direction in directions:\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    N = 1\n",
    "    direction_results[direction] = 0.0\n",
    "\n",
    "    for _ in range(N):\n",
    "        direction_results[direction] += get_results(force_data, phrase_data, merged_phrase_data, exclude_direction=direction, verbose=False)\n",
    "\n",
    "    direction_results[direction] /= N\n",
    "    plot_results(direction_results[direction], f\"Model Scores on Out-of-Distribution Directions ('{direction}')\")\n",
    "\n",
    "plot_results(np.mean([direction_results[direction] for direction in direction_results], axis=0), \"Model Scores on Out-of-Distribution Directions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
